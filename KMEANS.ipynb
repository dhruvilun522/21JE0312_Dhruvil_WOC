{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "training_data = pd.read_csv(\"emnist-letters-train.csv\",header=None)\n",
    "test_data = pd.read_csv(\"emnist-letters-train.csv\", header=None)\n",
    "X_train = training_data.iloc[:,0:].values\n",
    "X_test = test_data.iloc[:,0:].values\n",
    "l1=['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating distance and sorting it\n",
    "def distance(X_train,X_test):\n",
    "    distance = {}\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test )\n",
    "    \n",
    "    for i in range(X_test.shape[0]):\n",
    " \n",
    "            \n",
    "        dist = (((X_train - X_test[i,:])*2).sum(axis = 1))*(1/2)\n",
    "        dist = dist.reshape((X_train.shape[0],1))  \n",
    "        index = np.arange(0,X_train.shape[0])\n",
    "        index = index.reshape((X_train.shape[0],1))\n",
    "        dist = np.c_[index,dist]\n",
    "        distance[\"P\"+str(i+1)]= dist\n",
    "        distance['P'+str(i+1)] = distance['P'+str(i+1)][distance['P'+str(i+1)][:,1].argsort()]\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kmeans clustring\n",
    "centroid = np.array([]).reshape(X_train.shape[1],0)\n",
    "centroid_dict ={}\n",
    "accuracy={}\n",
    "\n",
    "k = 40\n",
    "for i in range(k):\n",
    "    rand = np.random.randint(0,X_train.shape[0],size = (1,1)).sum()\n",
    "    centroid = np.c_[centroid,X_train[rand]]\n",
    "    centroid_dict['Cluster'+str(i)]= X_train[rand]\n",
    "\n",
    "\n",
    "centroid = centroid.T\n",
    "initialcentroid = np.array(centroid)\n",
    "\n",
    "d=distance(centroid[:,1:],X_train[:,1:])\n",
    "\n",
    "\n",
    "for i in range(X_train.shape[0]):\n",
    "    point = X_train[i]\n",
    "    nearest_centroid = centroid[(int)(d['P'+str(i+1)][0][0])]\n",
    "    if (np.array_equal(point,initialcentroid[0]) | np.array_equal(point,initialcentroid[1]) ):\n",
    "        pass\n",
    "        \n",
    "    else:\n",
    "        centroid_dict['Cluster'+ str(((int)(d['P'+str(i+1)][0][0])))] = np.vstack((centroid_dict['Cluster'+str(((int)(d['P'+str(i+1)][0][0])))], point ))\n",
    "        new_centroid = (point + nearest_centroid)/2\n",
    "        centroid[(int)(d['P'+str(i+1)][0][0])] = new_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy testing\n",
    "for i in range(k):\n",
    "    vals,counts = np.unique(centroid_dict['Cluster'+str(i)][:,0],return_counts=True)\n",
    "    index = np.argmax(counts)\n",
    "    alphabet = l1[int(vals[index])-1]\n",
    "    print(\"Cluster of Alphabet \", alphabet)\n",
    "    print(\"Accuracy = \",(max(counts)/(centroid_dict['Cluster'+str(i)].shape[0]))*100)\n",
    "    accuracy['K '+str(k) +\" \" +str(i)] = (max(counts)/(centroid_dict['Cluster'+str(i)].shape[0]))*100"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "921a8fd9142323c132b692139857bb5e004fc1baf7b8adaa19d60dbedcb1b05b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
